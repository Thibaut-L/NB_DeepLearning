{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse de sentiments avec Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "### Just run this cell to load the data ###\n",
    "###########################################\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "def load_data(percentage_of_sentences=None):\n",
    "    train_data, test_data = tfds.load(name=\"imdb_reviews\", split=[\"train\", \"test\"], batch_size=-1, as_supervised=True)\n",
    "\n",
    "    train_sentences, y_train = tfds.as_numpy(train_data)\n",
    "    test_sentences, y_test = tfds.as_numpy(test_data)\n",
    "\n",
    "    # Take only a given percentage of the entire data\n",
    "    if percentage_of_sentences is not None:\n",
    "        assert(percentage_of_sentences> 0 and percentage_of_sentences<=100)\n",
    "\n",
    "        len_train = int(percentage_of_sentences/100*len(train_sentences))\n",
    "        train_sentences, y_train = train_sentences[:len_train], y_train[:len_train]\n",
    "\n",
    "        len_test = int(percentage_of_sentences/100*len(test_sentences))\n",
    "        test_sentences, y_test = test_sentences[:len_test], y_test[:len_test]\n",
    "\n",
    "    X_train = [text_to_word_sequence(_.decode(\"utf-8\")) for _ in train_sentences]\n",
    "    X_test = [text_to_word_sequence(_.decode(\"utf-8\")) for _ in test_sentences]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_data(percentage_of_sentences=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans l'exercice pr√©c√©dent, vous avez entra√Æn√© une repr√©sentation Word2vec et converti toutes vos phrases d'entra√Ænement afin de les introduire dans un RNN, comme le montre la premi√®re √©tape de cette figure :\n",
    "\n",
    "<img src=\"word2vec_representation.png\" width=\"400px\" />\n",
    "\n",
    "\n",
    "\n",
    "‚ùì Refaites exactement ce que vous avez fait dans l'exercice pr√©c√©dent. D'abord, entra√Ænez un mod√®le word2vec (avec les arguments que vous voulez) sur votre phrase d'entra√Ænement. Enregistrez-le dans la variable `word2vec`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R√©utilisons les fonctions de l'exercice pr√©c√©dent pour convertir vos donn√©es d'entra√Ænement et de test en quelque chose que vous pouvez introduire dans un RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Function to convert a sentence (list of words) into a matrix representing the words in the embedding space\n",
    "def embed_sentence(word2vec, sentence):\n",
    "    pass\n",
    "\n",
    "# Function that converts a list of sentences into a list of matrices\n",
    "def embedding(word2vec, sentences):\n",
    "    pass\n",
    "\n",
    "# Embed the training and test sentences\n",
    "\n",
    "\n",
    "\n",
    "# Pad the training and test embedded sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è Pour √™tre s√ªr que cela a fonctionn√©, v√©rifions ce qui suit pour `X_train_pad` et `X_test_pad` :\n",
    "- ce sont des tableaux numpy\n",
    "- ils sont tridimensionnels\n",
    "- la derni√®re dimension est la taille de votre espace d'embedding word2vec (vous pouvez l'obtenir avec `word2vec.wv.vector_size`)\n",
    "- la premi√®re dimension est la taille de vos `X_train` et `X_test`.\n",
    "\n",
    "‚úÖ **Bonne pratique** ‚úÖ De tels tests sont tr√®s importants ! Non seulement dans cet exercice, mais dans les applications de la vie r√©elle. Ils √©vitent de trouver des erreurs trop tard et de les laisser se propager dans tout le notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST ME\n",
    "for X in [X_train_pad, X_test_pad]:\n",
    "    assert type(X) == np.ndarray\n",
    "    assert X.shape[-1] == word2vec.wv.vector_size\n",
    "\n",
    "\n",
    "assert X_train_pad.shape[0] == len(X_train)\n",
    "assert X_test_pad.shape[0] == len(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "\n",
    "Il est toujours bon d'avoir un mod√®le tr√®s simple pour tester votre propre mod√®le - pour √™tre s√ªr que vous faites quelque chose de mieux qu'un algorithme tr√®s simple.\n",
    "\n",
    "‚ùì Quelle est votre accuracy de base ? Dans ce cas, votre base peut √™tre de pr√©dire le label qui est le plus pr√©sent dans `y_train` (bien s√ªr, si le jeu de donn√©es est √©quilibr√©, la pr√©cision de base est 1/n o√π n est le nombre de classes - 2 ici)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Le mod√®le\n",
    "\n",
    "‚ùì Cr√©ez un RNN avec les couches suivantes :\n",
    "- une couche `Masking`\n",
    "- une `LSTM` avec 20 unit√©s et la fonction d'activation `tanh`.\n",
    "- une couche `Dense` avec 10 unit√©s\n",
    "- une couche de sortie qui d√©pend de votre t√¢che (`sigmoid` parce qu'il s'agit d'un probl√®me de classification)\n",
    "\n",
    "Ensuite, compilez votre mod√®le (utiliser `rmsprop` comme optimiseur - au moins pour commencer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Entrainer le mod√®le sur vos donn√©es incorpor√©es et padd√©es - n'oubliez pas le crit√®re d'arr√™t pr√©coce.\n",
    "\n",
    "‚ùó **Remarque** ‚ùó Votre pr√©cision d√©pendra grandement de votre corpus d'entra√Ænement. Ici, assurez-vous simplement que votre performance est sup√©rieure au mod√®le de base (ce qui devrait √™tre le cas m√™me si vous n'avez charg√© que 20% des donn√©es IMDB initiales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì √âvaluer votre mod√®le sur l'ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec - Transfer Learning\n",
    "\n",
    "Votre pr√©cision, bien que sup√©rieure √† celle du mod√®le de base, peut √™tre assez faible. Il existe de nombreuses options pour l'am√©liorer, comme le nettoyage des donn√©es et l'am√©lioration de la qualit√© de l'int√©gration.\n",
    "\n",
    "Nous ne nous pencherons pas ici sur les strat√©gies de nettoyage des donn√©es. Essayons d'am√©liorer la qualit√© de notre embedding. Mais au lieu de simplement charger un corpus plus important, pourquoi ne pas profiter de l'embedding que d'autres ont entra√Æn√© ? En effet, la qualit√© d'un embedding, c'est-√†-dire la proximit√© des mots, peut √™tre d√©riv√©e de diff√©rentes t√¢ches. C'est exactement ce qu'est l'apprentissage par transfert.\n",
    "\n",
    "\n",
    "\n",
    "‚ùì Lister les diff√©rents mod√®les disponibles dans word2vec gr√¢ce √† cela :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "print(list(api.info()['models'].keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** ‚ùì Charger un des embeddings de word2vec pr√©-entra√Æn√©s. \n",
    "\n",
    "Vous pouvez le faire avec `api.load(the-model-of-your-choice)`, et le stocker dans `word2vec_transfer`\n",
    "\n",
    "<details>\n",
    "    <summary>üí° Piste</summary>\n",
    "    \n",
    "Le mod√®le `glove-wiki-gigaword-50` est un bon candidat pour commencer car il est plus petit (65 MB).\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì V√©rifier la taille du vocabulaire, mais aussi la taille de l'espace d'embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Faire l'embedding de `X_train` et `X_test`, comme dans la premi√®re question il y a les fonctions pour le faire ! (Il y a une l√©g√®re diff√©rence dans la fonction `embed_sentence_with_TF`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert a sentence (list of words) into a matrix representing the words in the embedding space\n",
    "def embed_sentence_with_TF(word2vec, sentence):\n",
    "    embedded_sentence = []\n",
    "    for word in sentence:\n",
    "        if word in word2vec:\n",
    "            embedded_sentence.append(word2vec[word])\n",
    "\n",
    "    return np.array(embedded_sentence)\n",
    "\n",
    "# Function that converts a list of sentences into a list of matrices\n",
    "def embedding(word2vec, sentences):\n",
    "    embed = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        embedded_sentence = embed_sentence_with_TF(word2vec, sentence)\n",
    "        embed.append(embedded_sentence)\n",
    "\n",
    "    return embed\n",
    "\n",
    "# Embed the training and test sentences\n",
    "X_train_embed_2 = embedding(word2vec_transfer, X_train)\n",
    "X_test_embed_2 = embedding(word2vec_transfer, X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Faire le padding et enregistrer dans `X_train_pad_2` and `X_test_pad_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì R√©initialisez un mod√®le et entra√Ænez-le sur vos nouvelles donn√©es !  √âvaluez-le sur votre ensemble de test et comparez-le √† votre pr√©cision pr√©c√©dente.\n",
    "\n",
    "‚ùó **Remarque** ‚ùó L'entra√Ænement peut prendre un certain temps. Vous pouvez simplement calculer 10 epochs (ce n'est **pas** une bonne pratique, il s'agit juste de ne pas attendre trop longtemps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parce que votre nouveau word2vec a √©t√© entra√Æn√© sur un grand corpus, il a une repr√©sentation pour de nombreux mots ! Bien plus qu'avec votre petit ensemble de donn√©es, d'autant plus que vous avez √©limin√© les mots qui n'√©taient pas pr√©sents plus d'un certain nombre de fois dans l'ensemble d'entra√Ænement. Pour cette raison, vous avez beaucoup plus de mots int√©gr√©s dans vos ensembles de formation et de test, ce qui rend chaque it√©ration plus longue qu'auparavant"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
